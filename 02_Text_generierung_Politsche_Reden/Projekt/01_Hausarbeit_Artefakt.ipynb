{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gliederung\n",
    "\n",
    "- 1. Abstract....................................................................................................03\n",
    "- 2. Enführung.................................................................................................03\n",
    "- 3. Aufgabenstellung......................................................................................03\n",
    "- 4. Methodik...................................................................................................04\n",
    "- 5. Artefakt......................................................................................................05\n",
    "    - 5.1 Daten............................................................................................06\n",
    "    - 5.2 Analyse........................................................................................13\n",
    "    - 5.3 Nutbarmachung...........................................................................24\n",
    "    - 5.4 Nutzung........................................................................................27\n",
    "- 6. Fazit..........................................................................................................29 \n",
    "- 7. Literaturverzeichnis...................................................................................31\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbildungsverzeichnis\n",
    "\n",
    "- **Abbildung 1** DASC-PM..........................................................................................04 \n",
    "- **Abbildung 2** Schlüsselbereich Daten.....................................................................06 \n",
    "- **Abbildung 3** Schlüsselbereich Analyse..................................................................13 \n",
    "- **Abbildung 4** Erste Architektur................................................................................16 \n",
    "- **Abbildung 5** Zweite Architektur..............................................................................18\n",
    "- **Abbildung 6** Dritte Architektur................................................................................20 \n",
    "- **Abbildung 7** Schlüsselbereich Nutzbarmachung...................................................24\n",
    "- **Abbildung 8** Schlüsselbereich Nutzung.................................................................27 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pfadverzeichnis\n",
    "\n",
    "abbildung_1 = \"04_Methodik_Bilder/DASC_PM.png\"\n",
    "abbildung_2 = \"04_Methodik_Bilder/Daten.png\"\n",
    "abbildung_3 = \"04_Methodik_Bilder/Analyse.png\"\n",
    "abbildung_4 = \"05_Modelle_Bilder/Modell_first.png\"\n",
    "abbildung_5 = \"05_Modelle_Bilder/Modell_second.png\"\n",
    "abbildung_6 = \"05_Modelle_Bilder/Modell_third.png\"\n",
    "abbildung_7 = \"04_Methodik_Bilder/Nutzbarmachung.png\"\n",
    "abbildung_8 = \"04_Methodik_Bilder/Nutzung.png\"\n",
    "\n",
    "train_process_1 = \"05_Modelle_Bilder/train_process_1.png\"\n",
    "train_process_2 = \"05_Modelle_Bilder/train_process_2.png\"\n",
    "train_process_3 = \"05_Modelle_Bilder/train_process_3.png\"\n",
    "\n",
    "trained_model_1 = \"03_Modell_trained/Architektur1/speechGeneration1.pickle\"\n",
    "trained_model_2 = \"03_Modell_trained/Architektur2/speechGeneration1.pickle\"\n",
    "trained_model_3 = \"03_Modell_trained/Architektur3/speechGeneration1.pickle\"\n",
    "\n",
    "encryption_trained_model_word_to_int = \"03_Modell_trained/Architektur1/word_to_int.speechGeneration1.pickle\"\n",
    "encryption_trained_model_int_to_word = \"03_Modell_trained/Architektur1/int_to_word.speechGeneration1.pickle\"\n",
    "\n",
    "data = \"06_TXT/\"\n",
    "\n",
    "wordEmbedding = \"07_Word_Embedding_V100/model.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Abstract \n",
    "\n",
    "Im vorliegenden Notebook wird ein Model erstellt, welches das Ziel hat, Wörter und Sätze anhand von im Bundestag gehaltenen Reden, zu generieren.<br> \n",
    "Das Problem, welches behandelt wird, stellt ein Klassifizierungsproblem aus dem Bereich des Natural Language Processing dar.<br>\n",
    "\n",
    "Durch das Herunterbrechen der Daten auf spezifische Politiker oder einzelnen Parteien können bei erfolgreicher Generierung, <br>Textstrukturierung sowie Meinung zu einem spezifischen Thema herausgefiltert generiert werden.<br> Weiterhin können die erfolgreich generierten Satz Strukturen genutzt werden, um als Vorlage für die Struktur zukünftig gehaltener reden zudienen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Einführung \n",
    "\n",
    "Mit der steigernden Relevanz von Daten und deren Verarbeitung im wirtschaftlichen Kontext, wird deren Analyse einen immer größer werdenden Stellenwert zugeschrieben. Der Bereich Data-Science erfreut sich damit in den letzten Jahren einer immer größeren werdenden Popularität. Vermehrt werden Prozesse angepasst, deren Gestaltung bisher auf Erfahrungswerten und Beobachtungen beruhten.<br>\n",
    "\n",
    "Mit der Möglichkeit immer größer werdende Datensätze zu speichern und auch Quantitative Datenmengen wie Bild, Ton und Schrift auszuwerten, werden immer mehr Tools welche auf dem Einsatz von Künstlicher Intelligenz beruhen, im Alltag eingesetzt (Ipsos, 2020). Besonders ist dieses Phänomen im Bereich des Natural Language Processing zu beobachten, da Chatbots und Sprachassistenten schon langen keine Seltenheit mehr darstellen.\n",
    "\n",
    "Die voranschreitende Entwicklung in diesen Bereich diente auch als Anstoß für die vorliegende Arbeit.<br> \n",
    "Mit dem Hintergrund das, dass Erstellen einer qualitativen Rede unter den Gesichtspunkten der Strukturierung und den inhaltlichen Aspekten einen großen Aufwand mit sich ziehen kann, ist die Idee, dass die Strukturierung von Reden mithilfe einer Vorlage der automatisch generierter Reden vereinfacht werden kann.<br> \n",
    "die Methodik zum Erstellen des Notebooks orientiert sich an einen bereits existierende Vorgehensmodelle aus dem Bereich Data-Science, welches im Kapitel 4 vorgestellt wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Aufgabenstellung\n",
    "\n",
    "Das Ziel, welches in der Auftragserklärung definiert worden ist, ist es ein Model mithilfe von im Bundestag gehaltenen Reden zu trainieren, sodass es schlussendlich in der Lage ist, eine eigene Rede mit einer grammatikalisch korrekten Satzstruktur und verständlichen Inhalt generieren zu können.\n",
    "\n",
    "Das Problem stellt ein Klassifikation Problem dar, da anhand der bereits verfassten Reden das nächste Wort vorhergesagt wird. Jedes Wort wird als eigene Klasse dargestellt. Durch das mehrmalige Wiederholen dieses Prozesses kann ein Zusammenhängender Text erstellt werden.\n",
    "Nach der erfolgreichen Generierung der Texte kann die Genauigkeit des Models mithilfe verschiedener Metriken validiert werden. Außerdem lässt sich mithilfe der generieren Texte eine Aussage darüber treffen ob das Model imstande ist, ein Grammatikalisch Korrekte sowie inhaltlich Sinnvolle Rede zu generieren. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methodik \n",
    "\n",
    "Das Vorgehen zur Erstellung des Notebooks und Bearbeitung der Fragestellung orientiert sich an dem DASC-PM (Data Science Process Modell).\n",
    "Der DASC-PM wurde von einer Arbeitsgruppe der Nordakademie entworfen welches als Ziel hat Klarheit darüber zu schaffen, inwiefern Data-Science als Disziplin von anderen abzugrenzen ist. Darauf aufbauend welche Besonderheiten in Data-Science Projekten auftauchen und welche Kompetenzen im Team vorhanden sein müssen, damit die saubere Durchführung des Projekts gewährleistet ist.(Neuhaus, et al. 2020)\n",
    "\n",
    "Der DASC PM ist in folgende vier Arbeitsphasen unterteilt:\n",
    "- Daten\n",
    "- Analyse\n",
    "- Nutzbarmachung\n",
    "- Nutzung\n",
    "\n",
    "Im Vorgehensmodell wird weiterhin beschrieben, dass die Arbeitsdomäne, in der das Projekt durchgeführt wird, übergreifend in jeder Phase betrachtet werden muss, da in den Arbeitsphasen Domänenspezifische Grenzen gesetzt sein können.<br>\n",
    "Außerdem sollte das Projekt unter Berücksichtigung der vorliegenden IT-Infrastruktur durchgeführt werden. Die IT-Infrastruktur sollte vor Projektbeginn neu bewertet werden, um auszuschließen, dass das Projekt in einer Arbeitsphase, durch die nicht gegebene Infrastruktur abgebrochen werden muss.(Neuhaus, et al. 2020)\n",
    "\n",
    "Eine Umfangreiche Beschreibung des Vorgehensmodells ist hier finden :<br>\n",
    "<https://www.nordakademie.de/sites/default/files/2020-02/20200220_DASC-PM%20%28002%29.pdf>\n",
    "<br>\n",
    "Zur Erstellung des Notebooks werden die einzelnen Phasen jeweils beschrieben und anschließend abgearbeitet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DASC_PM](04_Methodik_Bilder/DASC_PM.png)\n",
    "*Abbildung 1 DASC_PM (Neuhaus, et al. 2020, S.23)*\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Artefakt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3363,
     "status": "ok",
     "timestamp": 1635775128160,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "OALuUj-TmToz",
    "outputId": "71c0b21f-98cf-4d04-fee2-05cc00132bb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lukasdech/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "import tqdm \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1635777908434,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "Jly0sftlotLr"
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100 # Länge der trainierten Sequence (Anzahl Wörter Pro Beispiel)\n",
    "EMBEDDING_SIZE = 100  # Dimension des verwendeten Embeddings\n",
    "BATCH_SIZE = 128 # Größe des trainierten Batches\n",
    "EPOCHS = 10 # Anzahl der trianierten Epochen\n",
    "CV_MAX_FEATURES = 5000 # Größe des Vokabluar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Daten \n",
    "\n",
    "In der ersten Arbeitsphase werden alles spezifische Aufgaben, die zur Vorbereitung für die eigentliche Analyse dienen zusammengefasst.<br>Damit ist sowohl die Daten Akquisition verbunden also auch die Aufbereitung des Datensatzes und das Datenmanagement. Außerdem wird schon im Schritt der Daten Akquisition eine erste explorative Datenanalyse durchgeführt, anhand der Ergebnisse lassen sich dann nötige Schritte für die Aufbereitung des Datensatzes definieren.\n",
    "\n",
    "\n",
    "![Schlüsselbereich Daten](04_Methodik_Bilder/Daten.png)\n",
    "\n",
    "*Abbildung 2 Schlüsselbereich Daten (Neuhaus, et al. 2020, S.26)*\n",
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0C2oiK5qVSq"
   },
   "source": [
    "**Urpsrungsdatenquelle**\n",
    "\n",
    "\n",
    "Die Analyse der Ursprungsdatenquelle umfasst die Betrachtung von Faktoren, welche das Reibungslose Arbeiten im Projekt ermöglichen. <br>Vor allem der Beschaffungs- und Verwaltungsaufwand spielen dabei eine übergeordnete Rolle. Allerdings wird auch die Qualität des vorliegenden Datensatzes bewertet. \n",
    "Da die Erstellung des Notebooks in einzeln Arbeit erfolgt und damit der Zugriff auf die Daten nicht eingeschränkt ist und der Beschaffungs- und Verwaltungsaufwand gering ist, wird im folgenden auf diese Punkte nicht weiter eingegangen.\n",
    "\n",
    "Wie bereits in der Fragestellung dargestellt soll das Ziel des Notebooks sein, ein Model zu erarbeiten welches es ermöglicht auf Grundlage von Politischen Reden, Texte zu generieren.\n",
    "Als Datengrundlage wurden Plenarprotokolle gewählt. <br>\n",
    "Plenarprotokolle werden in jeder Sitzung des Bundestages von 3 Stenografen angefertigt, die Protokolle enthalten dabei neben den Gehaltenen Reden auch Zurufe, Fragen sowie die Tagesordnung.<br>\n",
    "Die Protokolle sind als TXT Dateien frei unter folgender URL als Download verfügbar:<br> (https://www.bundestag.de/dokumente/protokolle/plenarprotokolle) <br>\n",
    "\n",
    "Da die Daten unstrukturiert im TXT vorliegen, besteht ein Teil des Preprocessing darin die Daten in eine Form zu bringen, die es ermöglicht nur die gehaltenen Reden mit den vorhandenen Metadaten wie Name des Politikers oder Partei des Politikers zu verarbeiten.<br>\n",
    "Dieser Schritte wurden bereits im folgenden Repository bearbeitet:<br>\n",
    "(https://github.com/Datenschule/offenesparlament-data) <br>\n",
    "Hierbei wurden die Plenarprotokolle, die zu einzelnen Sitzungen angefertigt worden sind, bereits verarbeitet und in ein CSV Format überführt. Dies ermöglicht es nun die Daten in den folgenden Schritten für ein geeignetes Analyseverfahren vorzubereiten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1635775129921,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "oMZDihwwOiNM"
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "#Einlesen der Plenarprotokolle \n",
    "for i in range(171,175):\n",
    "    protokoll_path = f\"06_Data/{i}.csv\"\n",
    "    dfs.append(pd.read_csv(protokoll_path, encoding = 'unicode_escape', \n",
    "                           sep = \",\", error_bad_lines = False))\n",
    "    \n",
    "#Zusammenfügen der Einzelnen Plenarprotokolle als ein Pandas Dataframe\n",
    "speeches_concat = pd.concat(dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploartive Datenanalyse**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel der Explorativen Datenanalyse ist es ein besseres inhaltliches Verständnis über den vorliegenden Datensatz aufzubauen.<br>Mithilfe dessen kann geklärt werden, ob die Daten in ausreichender Menge zur Verfügung stehen und inwiefern die Qualität und Aussagekraft der Daten zur Beantwortung der Fragestellung genügt. Die Explorative Datenanalyse besteht dabei aus der Datenvisualisierung und der Anwendungen von statistischen Methoden. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1635775129922,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "_0ZALYvkuLnM",
    "outputId": "a1ec4902-9427-4791-98b5-766a8180da18",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13313 entries, 0 to 13312\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       13313 non-null  int64  \n",
      " 1   id               13313 non-null  int64  \n",
      " 2   profile_url      8659 non-null   object \n",
      " 3   sequence         13313 non-null  int64  \n",
      " 4   sitzung          13313 non-null  int64  \n",
      " 5   speaker          9346 non-null   object \n",
      " 6   speaker_cleaned  9345 non-null   object \n",
      " 7   speaker_fp       9345 non-null   object \n",
      " 8   speaker_key      8659 non-null   float64\n",
      " 9   speaker_party    7588 non-null   object \n",
      " 10  text             13313 non-null  object \n",
      " 11  top              13313 non-null  object \n",
      " 12  top_id           13313 non-null  int64  \n",
      " 13  type             13313 non-null  object \n",
      " 14  wahlperiode      13313 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Allgemeine Information über die Rohdaten \n",
    "speeches_concat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1635775129923,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "251_ndVyRzD8",
    "outputId": "6eb515bf-963c-4223-dc13-9be0860cc534",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>sequence</th>\n",
       "      <th>sitzung</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_cleaned</th>\n",
       "      <th>speaker_fp</th>\n",
       "      <th>speaker_key</th>\n",
       "      <th>speaker_party</th>\n",
       "      <th>text</th>\n",
       "      <th>top</th>\n",
       "      <th>top_id</th>\n",
       "      <th>type</th>\n",
       "      <th>wahlperiode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>542008</td>\n",
       "      <td>https://www.abgeordnetenwatch.de/profile/norbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>PrÃ¤sident Dr. Norbert Lammert</td>\n",
       "      <td>Dr. Norbert Lammert</td>\n",
       "      <td>norbert-lammert</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Die Sitzung ist erÃ¶ffnet. Nehmen Sie bitte Pl...</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>chair</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>542009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beifall</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>poi</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>542010</td>\n",
       "      <td>https://www.abgeordnetenwatch.de/profile/norbe...</td>\n",
       "      <td>2</td>\n",
       "      <td>165</td>\n",
       "      <td>PrÃ¤sident Dr. Norbert Lammert</td>\n",
       "      <td>Dr. Norbert Lammert</td>\n",
       "      <td>norbert-lammert</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ich rufe jetzt den Tagesordnungspunkt 19 auf:\\...</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>chair</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>542011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beifall bei der SPD sowie bei Abgeordneten der...</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>poi</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>542012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>Peer SteinbrÃ¼ck (SPD)</td>\n",
       "      <td>Peer SteinbrÃ¼ck</td>\n",
       "      <td>peer-steinbruck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spd</td>\n",
       "      <td>Herr PrÃ¤sident! Meine sehr geehrten Damen und...</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>speech</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>542013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lachen bei Abgeordneten der LINKEN</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>poi</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>542014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>165</td>\n",
       "      <td>Peer SteinbrÃ¼ck (SPD)</td>\n",
       "      <td>Peer SteinbrÃ¼ck</td>\n",
       "      <td>peer-steinbruck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spd</td>\n",
       "      <td>Die inzwischen sehr starke ideologische Auflad...</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>speech</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>542015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beifall bei Abgeordneten der SPD und der CDU/CSU</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>poi</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>542016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>165</td>\n",
       "      <td>Peer SteinbrÃ¼ck (SPD)</td>\n",
       "      <td>Peer SteinbrÃ¼ck</td>\n",
       "      <td>peer-steinbruck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spd</td>\n",
       "      <td>Wir sind zwar gelegentlich befremdet und halte...</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>speech</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>542017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beifall bei der SPD und der CDU/CSU</td>\n",
       "      <td>TOP 19 Weiterentwicklung der transatlantischen...</td>\n",
       "      <td>14821</td>\n",
       "      <td>poi</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                                        profile_url  \\\n",
       "0           0  542008  https://www.abgeordnetenwatch.de/profile/norbe...   \n",
       "1           1  542009                                                NaN   \n",
       "2           2  542010  https://www.abgeordnetenwatch.de/profile/norbe...   \n",
       "3           3  542011                                                NaN   \n",
       "4           4  542012                                                NaN   \n",
       "5           5  542013                                                NaN   \n",
       "6           6  542014                                                NaN   \n",
       "7           7  542015                                                NaN   \n",
       "8           8  542016                                                NaN   \n",
       "9           9  542017                                                NaN   \n",
       "\n",
       "   sequence  sitzung                         speaker      speaker_cleaned  \\\n",
       "0         0      165  PrÃ¤sident Dr. Norbert Lammert  Dr. Norbert Lammert   \n",
       "1         1      165                             NaN                  NaN   \n",
       "2         2      165  PrÃ¤sident Dr. Norbert Lammert  Dr. Norbert Lammert   \n",
       "3         3      165                             NaN                  NaN   \n",
       "4         4      165          Peer SteinbrÃ¼ck (SPD)     Peer SteinbrÃ¼ck   \n",
       "5         5      165                             NaN                  NaN   \n",
       "6         6      165          Peer SteinbrÃ¼ck (SPD)     Peer SteinbrÃ¼ck   \n",
       "7         7      165                             NaN                  NaN   \n",
       "8         8      165          Peer SteinbrÃ¼ck (SPD)     Peer SteinbrÃ¼ck   \n",
       "9         9      165                             NaN                  NaN   \n",
       "\n",
       "        speaker_fp  speaker_key speaker_party  \\\n",
       "0  norbert-lammert       1754.0           NaN   \n",
       "1              NaN          NaN           NaN   \n",
       "2  norbert-lammert       1754.0           NaN   \n",
       "3              NaN          NaN           NaN   \n",
       "4  peer-steinbruck          NaN           spd   \n",
       "5              NaN          NaN           NaN   \n",
       "6  peer-steinbruck          NaN           spd   \n",
       "7              NaN          NaN           NaN   \n",
       "8  peer-steinbruck          NaN           spd   \n",
       "9              NaN          NaN           NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  Die Sitzung ist erÃ¶ffnet. Nehmen Sie bitte Pl...   \n",
       "1                                            Beifall   \n",
       "2  Ich rufe jetzt den Tagesordnungspunkt 19 auf:\\...   \n",
       "3  Beifall bei der SPD sowie bei Abgeordneten der...   \n",
       "4  Herr PrÃ¤sident! Meine sehr geehrten Damen und...   \n",
       "5                 Lachen bei Abgeordneten der LINKEN   \n",
       "6  Die inzwischen sehr starke ideologische Auflad...   \n",
       "7   Beifall bei Abgeordneten der SPD und der CDU/CSU   \n",
       "8  Wir sind zwar gelegentlich befremdet und halte...   \n",
       "9                Beifall bei der SPD und der CDU/CSU   \n",
       "\n",
       "                                                 top  top_id    type  \\\n",
       "0  TOP 19 Weiterentwicklung der transatlantischen...   14821   chair   \n",
       "1  TOP 19 Weiterentwicklung der transatlantischen...   14821     poi   \n",
       "2  TOP 19 Weiterentwicklung der transatlantischen...   14821   chair   \n",
       "3  TOP 19 Weiterentwicklung der transatlantischen...   14821     poi   \n",
       "4  TOP 19 Weiterentwicklung der transatlantischen...   14821  speech   \n",
       "5  TOP 19 Weiterentwicklung der transatlantischen...   14821     poi   \n",
       "6  TOP 19 Weiterentwicklung der transatlantischen...   14821  speech   \n",
       "7  TOP 19 Weiterentwicklung der transatlantischen...   14821     poi   \n",
       "8  TOP 19 Weiterentwicklung der transatlantischen...   14821  speech   \n",
       "9  TOP 19 Weiterentwicklung der transatlantischen...   14821     poi   \n",
       "\n",
       "   wahlperiode  \n",
       "0           18  \n",
       "1           18  \n",
       "2           18  \n",
       "3           18  \n",
       "4           18  \n",
       "5           18  \n",
       "6           18  \n",
       "7           18  \n",
       "8           18  \n",
       "9           18  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ausgabe der ersten 10 Zeilen der Rohdaten\n",
    "speeches_concat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5641.000000\n",
      "mean       88.341783\n",
      "std        95.532146\n",
      "min         1.000000\n",
      "25%        28.000000\n",
      "50%        59.000000\n",
      "75%       113.000000\n",
      "max      1334.000000\n",
      "Name: text, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualiserung der Reden \n",
    "lens = speeches_concat[speeches_concat[\"type\"] == \"speech\"][\"text\"].str.split().apply(lambda x: len(x))\n",
    "print(lens.describe())\n",
    "lens.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datenaufbereitung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Grundlegende Ziel der Datenaufbereitung ist es, die Daten in eine Form zubringen das sich diese für ein ausgewähltes Analyseverfahren eignen.<br> \n",
    "Weiterhin werden mithilfe der Ergebnisse aus der Explorativen Datenanalyse werden weitere Änderung am Datensatz vorgenommen, um die Qualität der Daten zu steigern und um zu verhindern das Unstimmigkeiten im Datensatz für eine Verzerrung des Analyseergebnisses sorgen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqD19nlNsmcN"
   },
   "source": [
    "**Daten Filtern**<br>\n",
    "Wie in der Explorativen Datenanalyse dargestellt, ist zuerkennen das sich im Datensatz auch Beiträge befinden, die keine Politische Rede sind. <br>\n",
    "Schlussfolgernd werden alle Zeilen, welche nicht dem Typ Speech sind oder keiner Partei zugeordnet werden können, rausgefiltert.\n",
    "\n",
    "Außerdem werden nicht relevante Spalten entfernt.\n",
    "Für die weitere Verarbeitung werden nur die Texte benötigt, anhand der vorhandenen Metadaten wird der Datensatz außerdem auf nur eine Partei beschränkt, in diesem Fall die CDU / CSU, da dies die Partei mit den mitgehaltenen Reden im Datensatz ist.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1635775129923,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "6eAXfjYyVllJ"
   },
   "outputs": [],
   "source": [
    "#Filtern der Daten, sodass nur notwendige Daten erhalten bleiben \n",
    "filtered_column_speeches = speeches_concat[[\"speaker_party\",\"text\",\"top\",\"type\"]]\n",
    "filtered_row_speeches = filtered_column_speeches[\n",
    "                        (filtered_column_speeches[\"speaker_party\"].notnull()) &\n",
    "                        (filtered_column_speeches[\"type\"] == \"speech\") &\n",
    "                        (filtered_column_speeches[\"speaker_party\"] == \"cducsu\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1635775129924,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "IUmCu0aeiTH9",
    "outputId": "48176f3d-9465-4dd5-e8f3-e57b0062eff5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cducsu    272\n",
       "Name: speaker_party, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Anzahl an verschiedenen Reden im gesäuberten Datensatz\n",
    "filtered_row_speeches.speaker_party.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1635775129925,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "wB_FXr7CgOm5",
    "outputId": "62f0f96f-c410-4653-db78-b2f77f3086ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_party</th>\n",
       "      <th>text</th>\n",
       "      <th>top</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>cducsu</td>\n",
       "      <td>Sehr geehrter Herr PrÃ¤sident! Sehr verehrte K...</td>\n",
       "      <td>TOP 3 Informationsaustausch bei Terrorismusbek...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>cducsu</td>\n",
       "      <td>Das stimmt einfach nicht. Dieser Gesetzentwurf...</td>\n",
       "      <td>TOP 3 Informationsaustausch bei Terrorismusbek...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>cducsu</td>\n",
       "      <td>Zur Wahrheit gehÃ¶rt auch dazu, dass wir es mi...</td>\n",
       "      <td>TOP 3 Informationsaustausch bei Terrorismusbek...</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker_party                                               text  \\\n",
       "147        cducsu  Sehr geehrter Herr PrÃ¤sident! Sehr verehrte K...   \n",
       "149        cducsu  Das stimmt einfach nicht. Dieser Gesetzentwurf...   \n",
       "151        cducsu  Zur Wahrheit gehÃ¶rt auch dazu, dass wir es mi...   \n",
       "\n",
       "                                                   top    type  \n",
       "147  TOP 3 Informationsaustausch bei Terrorismusbek...  speech  \n",
       "149  TOP 3 Informationsaustausch bei Terrorismusbek...  speech  \n",
       "151  TOP 3 Informationsaustausch bei Terrorismusbek...  speech  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ersten 3 Zeilen des gesäuberten Datensatzes\n",
    "filtered_row_speeches.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcDa1MbFYrQU"
   },
   "source": [
    "**Vorbereitung Daten**<br>\n",
    "Nachdem alle Reden in einen zusammenhängenden Text transformiert worden sind, kann mithilfe eines Sets ausgewertet werden wie viele verschiedene Wörter sich im Datensatz befinden.\n",
    "\n",
    "Da Es sich bei einen NLP Problem um ein Klassifizierungsproblem handelt und Wörter untereinander Nominalskaliert werden besteht die Notwendigkeit die Daten zu One-Hot-Encoden, da das Modell ansonsten nicht vorhandene Zusammenhänge lernt.<br>\n",
    "Beim One-Hot-Encoding wird jedes Wort als Vektor dargestellt, die Länge des Vektors entspricht denn insgesamt zu lernenden Wörtern. Daraus resultiert das die Verarbeitungszeit, die das Modell zum Trainieren benötigt stark von der Anzahl an zu trainierende Wörter abhängt.\n",
    "\n",
    "Der Pool an verschiedenen Wörtern, welche im Datensatz vorhanden sind, wird auf die meist genutzten eingeschränkt, um die Trainingsdauer zu verringern und möglichst wenig Qualitätsverluste zuhaben.<br>\n",
    "Mithilfe eine word_tokenizers welcher den Text in einzelne Wörter zerlegt und einen Countvectorizer welcher es ermöglich den Datensatz auf die an den häufigsten genutzten Worten zu reduzieren wird der Datensatz eingeschränkt. \n",
    "\n",
    "Beding durch die Komplexität und die damit verbundene Dauer, die für das Training des Models benötigt wird. Ist die Maximal Anzahl an zu trainierenden Wörtern auf 5000 beschränkt, da dies dem aktiv genutzten Vokabular eines Muttersprachlers entspricht (Römer 2005).<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18749,
     "status": "ok",
     "timestamp": 1635775148661,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "W9fVgaxmnT-o",
    "outputId": "f68bf92f-6fa0-45e1-82d5-3ab4856ffd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5680\n"
     ]
    }
   ],
   "source": [
    "#Alle Reden als zusammenhängenden Text darstellen\n",
    "all_speeches_series = pd.Series(list(filtered_row_speeches[\"text\"]))\n",
    "all_speeches_text = all_speeches_series.str.cat(sep=' ')\n",
    "\n",
    "#Text in einezelne Wörter zerlegen \n",
    "tokens_speeches = word_tokenize(all_speeches_text)\n",
    "\n",
    "#Wie viele verschiedene Wörter sind vorhanden\n",
    "print(len(set(tokens_speeches)))\n",
    "\n",
    "#max_features = es werden sich nur die X Häufigsten Wörter angeschaut\n",
    "cv = CountVectorizer(max_features= CV_MAX_FEATURES, \n",
    "                     lowercase= False, token_pattern =\"(.*)\")\n",
    "cv.fit(tokens_speeches)\n",
    "\n",
    "#features = X Häufigsten Wörter\n",
    "features = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGktUFuCDGBZ"
   },
   "source": [
    "**Input vorbereiten**<br>\n",
    "Neuronale Netze können nur Zahlen als Input und Output verarbeiten.<br>\n",
    "Schlussfolgernd ist es notwendig jedem Wort eine Zahl zuzuordnen, um die Verarbeitung im Model zu ermöglichen und die umgekehrte Codierung von Zahl zu Wort ebenfalls abzuspeichern, damit es möglich ist die Vorhersage des Modells wieder in Schrift umzuwandeln.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1635777330155,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "5uf8bg9un4bz"
   },
   "outputs": [],
   "source": [
    "word_to_int = {}\n",
    "int_to_word = {}\n",
    "\n",
    "#jedes wort wird einer zahl zugeordnet\n",
    "for i in range(0, len(features)):\n",
    "    word = features[i]\n",
    "    word_to_int[word] = i\n",
    "    int_to_word[i] = word \n",
    "\n",
    "#Alle tokens wird in eine zahl umgewandelt allerdings nur die die auch zu denn 5000 meisten gehören\n",
    "tokens_transformed = [word_to_int[word] for word \n",
    "                      in tokens_speeches if word in word_to_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1635775187853,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "WtUfqlPTsm6p"
   },
   "outputs": [],
   "source": [
    "with open(\"word_to_int.speechGeneration.pickle\", \"wb\") as file:\n",
    "    pickle.dump(word_to_int, file)\n",
    "\n",
    "with open(\"int_to_word.speechGeneration.pickle\", \"wb\") as file:\n",
    "    pickle.dump(int_to_word, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obv-DDL2D14H"
   },
   "source": [
    "**Erstellung Trainingsdatensatz**<br>\n",
    "Anschließend werden die Daten in eine Form gebracht mit welchen das Training möglich ist.\n",
    "Da die Vorhersage des nächsten Wortes auf Grundlage des Kontextes erfolgen soll, sind die Inputvariablen eine Sequenz von Wörtern welche aufeinanderfolgend im Text vorkommen. Die Output Variable entspricht dem Wort, welches nach der Sequenz folgt.\n",
    "\n",
    "Das Ziel ist es damit dem Modell die Möglichkeit zugeben die Vorhersage anhand eines oder mehrere Sätze treffen zukönnen.\n",
    "\n",
    "Die Output Variablen werden One-Hot-encoded wodurch die Vorhersage von unabhängigen Klassen ermöglicht wird, wobei jedes Wort eine Klasse darstellt.\n",
    "Das One-Hot-Encoding bei den Input Variablen ist nicht notwendig, da die erste Schicht des Netzes ein Embedding Layer ist welches das One-Hot-Encoding übernimmt.\n",
    "\n",
    "**Testdatensatz**<br>\n",
    "Eine weiter Unterteilung zwischen Trainings- und Testdaten wird an dieser Stelle noch nicht vorgenommen, da nicht Alle Plenarprotokolle eingelesen worden sind und die nicht eingelesen Protokolle bei der Evaluierung der Ergebnisse als Testdatensatz dienen werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 15597,
     "status": "ok",
     "timestamp": 1635777347105,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "-oSJ1L22qtHJ"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "# x = vektor an zahlen (satz)\n",
    "# y = nächstes wort (One-Hot-Encoding) \n",
    "for i in range(0, len(tokens_transformed) - SEQUENCE_LENGTH):\n",
    "    X.append(tokens_transformed[i:i + SEQUENCE_LENGTH])\n",
    "    y.append(tokens_transformed[i+SEQUENCE_LENGTH])\n",
    "X = np.array(X)\n",
    "y = np.array(to_categorical(y, num_classes = cv.max_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Analyse\n",
    "***\n",
    "**Alle Vorgestellten Architekturen wurden bereits trainiert und mit als Prüfungsleistung abgeben. Die trainierten Modele werden im Kapitel der Ergebnis Evaluation vorgestellt.**\n",
    "***\n",
    "Nachdem der Datensatz aufbereitet ist, kann angepasst an den Anforderungen, ein geeignetes Analyseverfahren ausgewählt werden. Sobald ein geeignetes Verfahren gefunden worden ist, kann der Datensatz entsprechend verarbeitet werden und die Ergebnisse evaluiert werden. Im vorliegenden Notebook wurde sich aufgrund der Komplexen Aufgabenstellung für Deep-Learning als Analysemethode entscheiden. \n",
    "\n",
    "Im Folgenden wird zum einen die Grundlegende Theorie zu den genutzten Architekturen und Modellen vorgestellt, sowie der Code zum Trainieren der Modele erstellt. Anschließend werden die Ergebnisse anhand verschiedenere Metriken bewertet. \n",
    "\n",
    "\n",
    "![Schlüsselbereich Analyse](04_Methodik_Bilder/Analyse.png)\n",
    "*Abbildung 3 Schlüsselbereich Analyse (Neuhaus, et al. 2020, S.37)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aktivierungsfunktion**\n",
    "\n",
    "Sigmoid<br>\n",
    "die Sigmoid-Funktion besitzt eine große Signalverstärkung im zentralen Bereich und nur eine kleine Signalverstärkung an den äußeren Bereichen, dies führt dazu das die Werte vermehrt gegen 1 oder 0 tangieren wodurch erkannte Eigenschaften verstärkt werden (Chigozie, Enyinna, Nwankpa 2020).\n",
    "\n",
    "Softmax<br>\n",
    "Die Softmax definiert anhand der Inputvariablen für jeden Output eine Wahrscheinlichkeit.\n",
    "die Summe der definierten Wahrscheinlichkeiten ist 1, da die Softmax Aktivierungsfunktion in den Beispielen, als Aktivierungsfunktion für den letzten Dense_Layer gewählt worden ist wird das Wort welches den höchsten Wert zugewiesen bekommt als vorraussage definiert (Chigozie, Enyinna, Nwankpa 2020). \n",
    "***\n",
    "**Layer**\n",
    "\n",
    "Dense Layer<br>\n",
    "Der Dense Layer wird auch als Fully Connected Layer bezeichnet. Es handelt sich hier um eine Standartschicht, bei der alle Neuronen mit sämtlichen Inputs und Outputs verbunden sind. In dem letzten Dense Layer findet die endgültige Klassifizierung statt (Emmert-Streib F 2020).\n",
    "\n",
    "Dropout Layer<br>\n",
    "Der Dropout Layer ist eine Prävention für mögliches Overffitting.\n",
    "Dabei werden beim Training des Netzes eine definierte Anzahl von Neuronen beim nächsten Berechnungsschritt nicht beachtet. Das hat zufolge, dass, das Training des Netzes meist langsamer ist und sich weniger an die Trainingsdaten anpasst. Damit kann ein zu großer Dropout auch negative Folgen haben, allerdings ist es eine Möglichkeit, mögliches auswendig lernen des Netzes zu verhindern (Emmert-Streib F 2020).\n",
    "\n",
    "LSTM_Layer(Long-Short-Term-Memory)<br>\n",
    "LSTM_Layer sind die Weiterentwicklung von RNN Layer, LSTM Laer verfügen über die Eigenschaft, vergangen Informationen in Sequenzen zu selektieren. Damit besitzen diese die Eigenschaft aus Vergangenen Werten die Informationen Herauszufiltern, die für den aktuellen Output relevant sind und welche nicht notwendig sind und somit vergessen werden können.\n",
    "Damit verwenden LSTM_Layer vermehrt in der Zeitreihenanalyse oder im NLP Bereich eingesetzt, da es sich dabei immer um Daten handelt die als Sequenz vorliegen (Emmert-Streib F 2020).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SNiUFzbHHVT"
   },
   "source": [
    "**Word Embeddings**<br>\n",
    "Alle im folgenden vorgestellten Architekturen beinhalten ein Embedding Layer bei welchen die Matrix auf ein Word Embedding basiert. <br>\n",
    "\n",
    "Beim Word Embedding wird ein Wort nicht als Ziffer dargestellt, sondern als Vektor im vektorraum dargestellt wodurch es möglich ist verschiedene Relationen zwischen den einzelnen Wörtern erkennbar zu machen. Je näher die Vektoren beieinander liegen\n",
    "desto eher stimmt die Bedeutung der Wörter überein oder die Wörter werden im gleichen Kontext verwendet. <br>\n",
    "Die Darstellung im Vektorraum ermöglicht es den Neuronalen Netz die Vorhersage des nächsten Wortes anhand des vorhandenen Kontextes vorherzusagen (Bengio 2014).<br>\n",
    "Für die vorgestellten Modelle wurde vermehrt ein Pretrained Word Embedding genutzt.\n",
    "Ausgewähltes Embedding: German CoNLL17 corpus vektor size 100<br> (http://vectors.nlpl.eu/repository/)<br>\n",
    "\n",
    "**Embedding einbinden**<br>\n",
    "Das Word Embedding wurde aufgrund der Dateiengröße nicht als Prüfungsleistung mit abgegeben. Zum einbinden des Embeddings muss diese unter den angegeben Link gedownloadet werden und die dazugehörig Text Datei muss unter folgenden Pfad mit dem Namen \"model.txt“ abgelegt werden:\n",
    "07_Word_Embedding_V100/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1635777127073,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "GD11tBHv1kN0"
   },
   "outputs": [],
   "source": [
    "def get_embedding_vectors(dim=100):\n",
    "    embedding_index = {}\n",
    "    #Einlesen Pretrained Embedding\n",
    "    with open(f\"07_Word_Embedding_V100/model.txt\", \n",
    "              encoding='unicode_escape') as f:\n",
    "        for line in tqdm.tqdm(f, \"Reading Embedding\"):\n",
    "  \n",
    "            values = line.split()\n",
    "            if not values:\n",
    "              break\n",
    "            try:\n",
    "                #Erster Wert im Array ist immer das Wort\n",
    "                word = values[0]\n",
    "                #Restlichen Werte repräsentieren den Vektor\n",
    "                vectors = np.asarray(values[1:], dtype='float64')\n",
    "                embedding_index[word] = vectors\n",
    "            except ValueError:            \n",
    "                pass\n",
    "    word_index = word_to_int\n",
    "    embedding_matrix = np.zeros((len(word_index), dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auswahl Analyseverfahren** \n",
    "\n",
    "Bedingt dadurch das die Auswahl einer geeignten Architektur sowie die Einstellung diverser Hyperparameter ein Iteratives Verfahren ist, werden im folgende verschiedene Archtiekturen trainiert und die Ergebnisse bewertet.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOKjLkwP9A5E"
   },
   "source": [
    "**Erste Architektur**<br>\n",
    "Für das Model werden sowohl LSTM Layer als auch Embedding Layer verwendet als Output Layer sowie als letzter Hiddenlayer wird ein Dense Layer verwendet.\n",
    "\n",
    "Die Idee hinter der Architektur war es, dass mithilfe \n",
    "Die Input Sequenz von zwei Embedding Layer verarbeitet wird, damit zum einen das Model in der Lage ist durch das Pretrained Embedding das nächste Wort anhand des Kontexts vorherzusagen und das durch den zweiten Embedding Layer die Gewichte vermehrt, auf die im Text häufig vorkommenden Wörter gelegt werden. Weiterhin wurden als Hidden layer LSTM Layer verwendet damit die vom Embedding Layer übergebene Sequenz erhalten bleibt. Um ein mögliches gegen ein mögliches Overfitting vorzugehen, wurde auch ein Dropout von 15% der Verbindung zwischen Layern geschaltet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_Modelle_Bilder/Modell_first.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "*Abbildung 4 Erste Architektur (Eigene Darstellung)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6000,
     "status": "ok",
     "timestamp": 1635777353074,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "UiFsoKV2rnH5",
    "outputId": "b6a0cbb3-ddd6-4735-9c91-f89d65cbf40b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '07_Word_Embedding_V100/model.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ce5eb4b9566a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Input_Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-2e02fd3c402f>\u001b[0m in \u001b[0;36mget_embedding_vectors\u001b[0;34m(dim)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0membedding_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Einlesen Pretrained Embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     with open(f\"07_Word_Embedding_V100/model.txt\", \n\u001b[0m\u001b[1;32m      5\u001b[0m               encoding='unicode_escape') as f:\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reading Embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '07_Word_Embedding_V100/model.txt'"
     ]
    }
   ],
   "source": [
    "embedding_matrix = get_embedding_vectors()\n",
    "#Input_Layer\n",
    "input1 = layers.Input((SEQUENCE_LENGTH))\n",
    "input2 = layers.Input((SEQUENCE_LENGTH))\n",
    "\n",
    "#Embedding_Layer\n",
    "pretrained_Embedding = layers.Embedding(cv.max_features,\n",
    "                       EMBEDDING_SIZE,\n",
    "                       weights=[embedding_matrix],\n",
    "                       trainable=False,\n",
    "                       input_length=SEQUENCE_LENGTH)(input1)\n",
    "\n",
    "selftrained_Embedding = layers.Embedding(cv.max_features, \n",
    "                        EMBEDDING_SIZE,\n",
    "                        trainable=True,\n",
    "                        input_length=SEQUENCE_LENGTH)(input2)\n",
    "\n",
    "#Embedding_Layer zusammenfügen\n",
    "layerlist = [pretrained_Embedding, selftrained_Embedding]\n",
    "concat = layers.Concatenate(axis = -1)(layerlist)\n",
    "#LSTM first Hiddenlayer\n",
    "first_LSTM = layers.LSTM(256, return_sequences = True)(concat)\n",
    "#Dropout (Präventativ gegen mögliches overfitting)\n",
    "dropout_015 = layers.Dropout(0.15)(first_LSTM)\n",
    "#LSTM second Hiddenlayer\n",
    "second_LSTM = layers.LSTM(256, return_sequences = False)(first_LSTM)\n",
    "#Dense third Hiddenlayer\n",
    "first_dense = layers.Dense(10000,activation= \"sigmoid\")(second_LSTM)\n",
    "#Dense Output_Layer\n",
    "output = layers.Dense(cv.max_features, activation=\"softmax\")(second_LSTM)\n",
    "\n",
    "#Model Trainieren \n",
    "model = models.Model([input1,input2],output)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\",tf.keras.metrics.Precision(), \n",
    "                       tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1635775183367,
     "user": {
      "displayName": "lukas dech",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04425659372259947732"
     },
     "user_tz": -60
    },
    "id": "W6NtQjAz5t71"
   },
   "outputs": [],
   "source": [
    "#Model trainieren und abspeichern \n",
    "model.fit([X,X],y, batch_size=BATCH_SIZE, epochs=EPOCHS,verbose=1)\n",
    "model.save(\"speechGeneration1.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_Modelle_Bilder/train_process_1.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zweite Architektur**<br>\n",
    "Die zweite Architektur ist ähnlich aufgebaut wie die erst Architektur, jedoch verlaufen alle Layer sequentiell und es wird nur mit einen Embedding Layer und den Pretrained Word Embedding gearbeitet. Da die beiden Architekturen ähnlich sind können die Ergebnisse Aufschluss darüber geben, ob sich das Parallel schalten der Embeddinglayer negativ oder positiv auf das Ergebnis ausgewirkt hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_Modelle_Bilder/Modell_second.png\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "*Abbildung 5 Zweite Architektur (Eigene Darstellung)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '07_Word_Embedding_V100/model.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e424eccf0e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model.add(Embedding(cv.max_features,\n\u001b[0;32m----> 4\u001b[0;31m                     \u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_embedding_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     input_length=SEQUENCE_LENGTH))\n",
      "\u001b[0;32m<ipython-input-37-2e02fd3c402f>\u001b[0m in \u001b[0;36mget_embedding_vectors\u001b[0;34m(dim)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0membedding_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Einlesen Pretrained Embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     with open(f\"07_Word_Embedding_V100/model.txt\", \n\u001b[0m\u001b[1;32m      5\u001b[0m               encoding='unicode_escape') as f:\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reading Embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '07_Word_Embedding_V100/model.txt'"
     ]
    }
   ],
   "source": [
    "#Model Initalisieren und Hyperparamter einstellen\n",
    "model = Sequential()\n",
    "model.add(Embedding(cv.max_features,\n",
    "                    EMBEDDING_SIZE,weights=[get_embedding_vectors()],\n",
    "                    trainable=False,\n",
    "                    input_length=SEQUENCE_LENGTH))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(10000,activation= \"sigmoid\"))\n",
    "model.add(Dense(cv.max_features, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\",tf.keras.metrics.Precision(),\n",
    "                       tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model trainieren und abspeichern \n",
    "model.fit(X,y,batch_size=BATCH_SIZE, epochs=EPOCHS,verbose=1)\n",
    "model.save(\"speechGeneration2.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_Modelle_Bilder/train_process_2.png\" alt=\"drawing\" width=\"900\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dritte Architektur**<br>\n",
    "Die Dritte Architektur basiert vermehrt auf der Nutzung von LSTM Layern.\n",
    "Dabei ist der erste Input Layer wie in den vorangegangenen Modellen ein Embedding Layer, danach werden abwechselnd LSTM Layer und Dropout Layer hintereinander geschaltet.\n",
    "\n",
    "Wie bei den anderen Architekturen ist auch bei dieser der Output Layer ein Dense Layer, bei welchen die Anzahl an Neuronen den trainierten Vokabular entspricht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_Modelle_Bilder/Modell_third.png\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "*Abbildung 6 Dritte Architektur (Eigene Darstellung)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading GloVe: 142115it [00:04, 33695.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#Model Initalisieren und Hyperparamter einstellen\n",
    "model = Sequential()\n",
    "model.add(Embedding(cv.max_features,\n",
    "                    EMBEDDING_SIZE,weights=[get_embedding_vectors()],\n",
    "                    trainable=False,\n",
    "                    input_length=SEQUENCE_LENGTH))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(cv.max_features, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\",tf.keras.metrics.Precision(),\n",
    "                       tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model trainieren und abspeichern \n",
    "model.fit(X,y,batch_size=BATCH_SIZE, epochs=EPOCHS,verbose=1)\n",
    "model.save(\"speechGeneration3.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"05_Modelle_Bilder/train_process_3.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ergebnisse Evaluieren**<br>\n",
    "Zur Evaluierung der Ergebnisse wird die Performance jedes Modells anhand\n",
    "folgender Metriken gemessen: loss, accuracy, precision, recall  \n",
    "\n",
    "Damit die genannten Parameter ermittelt werden können wird ein bisher noch nicht betrachtetes Plenarprotokoll eingelesen und durchläuft den gleichen Preprocessing Prozess wie die Trainingsdaten.\n",
    "\n",
    "Anschließend können die trainierten und geladenen Modelle, anhand einer Eingabe Sequenz aus dem Plenarprotokoll, die darauf folgenden Wörter vorhersagen. Die Anschließende Bewertung der Ergebnisse erfolgt im Fazit.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erklärung Metriken**\n",
    "\n",
    "**loss**<br>\n",
    "Im Verhältnis zu den anderen Werten ist der Loss keine Prozentangabe. Loss ist die Summe von Fehlern, die für jedes Beispiel gemacht worden sind. Damit weist eine niedrigere Zahl auf eine bessere Performance hin, eine zu niedriger Loss auf Trainingsdaten kann auch ein Anzeichen von Overfitting sein.\n",
    "\n",
    "**accuracy**<br>\n",
    "Treffer Wahrscheinlichkeit, wie oft wurde tatsächlich die richtige Klasse vorhergesagt\n",
    "\n",
    "**precision**<br>\n",
    "Das Verhältnis von Positiv richtig vorhergesagten Werten zu den generell positiv vorhergesagten Werten. <br>\n",
    "True_Positiv/True_Positiv+False_Positiv\n",
    "\n",
    "**recall**<br>\n",
    "Verhältnis von allen Positiv Richtig vorhersagen eins Worts zu den insgesamten Möglichkeiten eine richtige Vorhersage zutreffen<br>\n",
    "True_Positiv/True_Positiv+False_Negativ\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model('03_Modell_trained/Architektur1/speechGeneration1.pickle')\n",
    "#Model 2 und 3 konnten bei der Abgabe per Mail, aufgrund der Größe, nicht mit abgeben werden.\n",
    "\n",
    "#model2 = keras.models.load_model('03_Modell_trained/Architektur2/speechGeneration2.pickle')\n",
    "#model3 = keras.models.load_model('03_Modell_trained/Architektur3/speechGeneration3.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"03_Modell_trained/Architektur1/word_to_int.speechGeneration1.pickle\", \"rb\")as file:\n",
    "    word_to_int = pickle.load(file)\n",
    "    \n",
    "with open(\"03_Modell_trained/Architektur1/int_to_word.speechGeneration1.pickle\", \"rb\") as file:\n",
    "    int_to_word = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagen : Wir dÃ¼rfen hier nicht zu viel Zeit verlieren . Wir haben es ja in den letzten Monaten erlebt : am 13 . November der schreckliche in , am 12 . Januar der in Istanbul , dem deutsche zum Opfer gefallen sind , am 22 . MÃ¤rz der in BrÃ¼ssel mit zahlreichen . Was in BrÃ¼ssel , was in , was in Istanbul , was in geschehen ist , kann auch jeden Tag in MÃ¼nchen , in oder hier in Berlin passieren . Wir sind in der Verantwortung und mÃ¼ssen deshalb fÃ¼r unsere die und gesetzlichen Rahmenbedingungen schaffen .\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for i in range(176,177):\n",
    "    protokoll_path = f\"06_Data/{i}.csv\"\n",
    "    dfs.append(pd.read_csv(protokoll_path, encoding= 'unicode_escape', \n",
    "                           sep = \",\", error_bad_lines= False))\n",
    "#Zusammenfügen der einzelnen Protokolle im Pandas Df\n",
    "speeches_concat = pd.concat(dfs, ignore_index= True)\n",
    "#Filtern der Daten, sodass nur notwendige Daten erhalten bleiben \n",
    "filtered_column_speeches = speeches_concat[[\"speaker_party\",\"text\",\"top\",\"type\"]]\n",
    "filtered_row_speeches = filtered_column_speeches[\n",
    "                            (filtered_column_speeches[\"speaker_party\"].notnull()) &\n",
    "                            (filtered_column_speeches[\"type\"] == \"speech\") &\n",
    "                            (filtered_column_speeches[\"speaker_party\"] == \"cducsu\")]\n",
    "#Alle Reden als zusammenhängenden Text darstellen\n",
    "all_speeches_series = pd.Series(list(filtered_row_speeches[\"text\"]))\n",
    "all_speeches_text = all_speeches_series.str.cat(sep=' ')\n",
    "#Text in einezelne Wörter zerlegen \n",
    "tokens_speeches = word_tokenize(all_speeches_text)\n",
    "tokens_transformed = [word_to_int[word] for word in tokens_speeches if word in word_to_int]\n",
    "X = []\n",
    "y = []\n",
    "# x = vektor an zahlen (satz)\n",
    "# y = nächstes wort (One-Hot-Encoding) \n",
    "for i in range(0, len(tokens_transformed) - SEQUENCE_LENGTH):\n",
    "    X.append(tokens_transformed[i:i + SEQUENCE_LENGTH])\n",
    "    y.append(tokens_transformed[i+SEQUENCE_LENGTH])\n",
    "X = np.array(X)\n",
    "y = np.array(to_categorical(y, num_classes = cv.max_features))\n",
    "sentence = tokens_transformed[100:200]\n",
    "print(\" \".join([int_to_word[token] for token in sentence]))\n",
    "sentence = np.array(tokens_transformed[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = model1.evaluate([X,X], y, verbose=0)\n",
    "#score2 = model2.evaluate(X, y, verbose=0)\n",
    "#score3 = model3.evaluate(X, y, verbose=0)\n",
    "\n",
    "print(f\"{model2.metrics_names[0]}/{model2.metrics_names[1]}/{model2.metrics_names[2]}/{model2.metrics_names[3]}\")\n",
    "print(f\"Modell_1: {score1[0]} / {score1[1]}  / {score1[2]}  / {score1[3]}\")\n",
    "#print(f\"Modell_2: {score2[0]}  / {score2[1]} / {score2[2]} / {score2[3]}\")\n",
    "#print(f\"Modell_3: {score3[0]} / {score3[1]} / {score3[2]}  / {score3[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Nutzbarmachung\n",
    "\n",
    "Damit die gewonnen Erkenntnisse oder Das Modell nutzbar gemacht werden können, muss nach Ziel des Projektes ausgewählt werden in welcher Form die Daten bereitgestellt werden sollen. Sobald das Ziel definiert ist, muss die Sowohl die technische Umsetzbarkeit geprüft werden als auch die Anwendbarkeit. Sollte beides gegeben sein könne die Analyse Ergebnisse bereitgestellt werden.<br>Da bisher nur die Metriken der Modelle geprüft worden sind, werden im Folgenden die Modelle für den eigentlichen nutzen vorbereitet und dazu verwendet Texte vorherzusagen.\n",
    "Dabei werden die vorhergesagten Klassen der Modelle zurück in die Vorhergesagten Wörter codiert, um zu erkennen wie Sinnvoll der generierte Inhalt und Satzstruktur ist.\n",
    "\n",
    "\n",
    "![Schlüsselbereich Nutzbarmachung](04_Methodik_Bilder/Nutzbarmachung.png)\n",
    "*Abbildung 7 Schlüsselbereich Nutzbarmachung (Neuhaus, et al. 2020, S.53)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \\nPrediction Model_1: \\n\")\n",
    "for i in range(0, 100):\n",
    "    prediction = model1.predict([sentence.reshape(1, 100),\n",
    "                                 sentence.reshape(1, 100)])\n",
    "    word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "    print(int_to_word[word], end=\" \")\n",
    "    sentence = np.append(sentence[1:], [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\" \\nPrediction Model_2: \\n\")\n",
    "#for i in range(0, 100):\n",
    "#    prediction = model2.predict([sentence.reshape(1, 100),\n",
    "#                                 sentence.reshape(1, 100)])\n",
    "#    word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "#    print(int_to_word[word], end=\" \")\n",
    "#    sentence = np.append(sentence[1:], [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\" \\nPrediction Model_3: \\n\")\n",
    "#for i in range(0, 100):\n",
    "#    prediction = model3.predict([sentence.reshape(1, 100),\n",
    "#                                 sentence.reshape(1, 100)])\n",
    "#    word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "#    print(int_to_word[word], end=\" \")   \n",
    "#    sentence = np.append(sentence[1:], [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Nutzung\n",
    "\n",
    "Nach dem die Ergebnisse so weit aufbereitet worden sind, dass diese im laufenden Betrieb genutzt werden können, muss in der weiterführenden Anwendung gewährleistet werden, dass das Modell weiterhin überwacht wird. Die Überwachung ist notwendig da sich die Datenlage im Betrieb, im Verhältnis zur Testdatenlage signifikant geändert haben kann, wodurch die Genauigkeit des Modells im Livebetrieb gebärdet ist. Außerdem müssen die gewonnen Ergebnisse in der zuständigen Fachabteilung Verwendung finden.<br>\n",
    "Da das Ziel war die generierten Texte bereitzustellen und anhand dessen zukünftige Reden anzupassen, erfolgt die Nutzung durch das Generieren einer Text Datei.\n",
    "In die Text Datei werden von trainierten Architekturen, jeweils die nächsten 250 auf eine Eingabe Sequenz vorhergesagt. Der eigentliche Nutzen und Erfüllung des Ziel erfolgt demnach mit der Benutzung der Textdatei als Vorlage für den Nutzer.   \n",
    "\n",
    "**Eine generiete Textdatei wurde dabei bereits mit als Prüfungsleistung abgegeben**\n",
    "![Schlüsselbereich Nutzung](04_Methodik_Bilder/Nutzung.png)\n",
    "*Abbildung 8 Schlüsselbereich Nutzung (Neuhaus, et al. 2020, S.66)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generierter_Text.txt', 'w') as f:\n",
    "    \n",
    "    f.write(\"\\nEingabe Sequenz:\\n \\n\")\n",
    "    f.write(\" \".join([int_to_word[token] for token in sentence]))\n",
    "    f.write(\"\\n \\n \\n\")\n",
    "    \n",
    "    f.write(\"\\nText generiert mit der ersten Architektur: \\n \\n\")\n",
    "    for i in range(0, 250):\n",
    "        prediction = model1.predict([sentence.reshape(1, 100)\n",
    "                                     ,sentence.reshape(1, 100)])\n",
    "        word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "        f.write(int_to_word[word])\n",
    "        f.write(\" \")\n",
    "        sentence = np.append(sentence[1:], [word])\n",
    "        \n",
    "    #f.write(\"\\n \\n \\n\")\n",
    "    #f.write(\"\\nText generiert mit der zweiten Architektur: \\n \\n\")   \n",
    "    #for i in range(0, 250):\n",
    "    #    prediction = model2.predict([sentence.reshape(1, 100)\n",
    "    #                                 ,sentence.reshape(1, 100)])\n",
    "    #    word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "    #    f.write(int_to_word[word])\n",
    "    #    f.write(\" \")\n",
    "    #    sentence = np.append(sentence[1:], [word])\n",
    "        \n",
    "    #f.write(\"\\n \\n \\n\")\n",
    "    #f.write(\"\\nText generiert mit der dritten Architektur: \\n \\n\")   \n",
    "    #for i in range(0, 250):\n",
    "    #    prediction = model3.predict([sentence.reshape(1, 100)\n",
    "    #                                 ,sentence.reshape(1, 100)])\n",
    "    #    word = np.random.choice(len(int_to_word), p=prediction[0])\n",
    "    #    f.write(int_to_word[word])\n",
    "    #    f.write(\" \")\n",
    "    #    sentence = np.append(sentence[1:], [word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fazit\n",
    "\n",
    "Das Ziel des Artefaktes wurde insofern erreicht, da es möglich war ein Model zu entwickeln welches in der Lage ist eine Text basierend auf den eingelesenen Plenarprotokollen zu generieren.<br>\n",
    "Allerdings hat die Verwendung des Models gezeigt, dass die generierten Textstrukturen sowie die Grammatik nicht den Anforderung entsprechend sind, um das Model als Vorlage für zukünftig geschriebene Reden zu verwenden.\n",
    "\n",
    "Die ermittelten Metriken deuteten bereits darauf hin, dass die Ergebnisse nicht den Anforderungen entsprechen werden. Zwar ist eine Accuracy von 15-20% bei einer Anzahl von 5000 Klasen weitaus besser als eine Zufällige Vorhersage, dennoch wird dabei nur jedes 5te Wort richtig vorhergesagt. <br>\n",
    "Sätze besitzen eine empfohlene durchschnittslänge von 15 Wörtern, damit sind pro Satz ohne Betrachtung der Satzeichen, nur 3 Wörter richtig vorhergesagt. Die damit Verbunde Anzahl an richtig vorhergesagten Worten reicht also nicht aus, um einen qualitativ hochwertigen Text zu generieren oder verständlichen Inhalt aufzuzeigen.\n",
    "\n",
    "Zum einen lässt sich die mindere Qualität der generierten Texte auf das eingeschränkte Vokabular zurückführen, da die eingelesen Texte bereits 20000 verschiedene Wörter beinhalteten. <br>Eine Möglichkeit die Qualität der Texte zu steigern, wäre es das Vokabular zu erweitern. Damit würde allerdings die Trainingsdauer zunehmen und diese betrug bereits bei einen Vokabular von 5000 Wörtern und 10 Trainingsepochen, über 15 Stunden.\n",
    "\n",
    "Wie bereits aufgezeigt beläuft sich das aktiv genutzte Vokabular von Muttersprachlern auf 5000 Wörtern. Allerdings ist dabei zu betrachten, dass es sich dabei um verschiedene Wörter handelt. Das Model hingegen stellt jede Änderung eines Wortes als eigene Klasse dar. <br>\n",
    "Schlussfolgernd daraus sind auch alle Konjugation von Verben eigenständige Wörter. Wodurch unter dem erlernten Vokabular auch etliche Wörter sind, welche angepasst an gegebene die gegeben Personalpronomen oder Zeitformen, mehrmals erlernt worden sind.\n",
    "\n",
    "Damit besteht die Möglichkeit den generieten Text, bei gleichbleibender Trainingsdauer zu verbessern, indem alle Wörter im Trainingsdatensatz auf dessen Infinitiv heruntergebrochen werden.  Allerdings würde damit auch die Grammatikalische Struktur des Textes verschlechtert werden.\n",
    "\n",
    "\n",
    "Außerdem konnte ein Ergebnis bei der Betrachtung der unterschiedlichen Architekturen erzielt werden. \n",
    "Das erste Model wurde mit 2 Embedding Layer gebaut und ein 15% Dropout zwischen den LSTM Layern, abgesehen davon war es identisch mit der zweiten Architektur. Anhand der Metriken ist zu erkennen, dass die erste Architektur auf den Testdatensatz eine bessere Performance hatte, außerdem war auch die Performance, des ersten Modells auf den Trainingssatz besser. Resultierend daraus ist bessere Performance des ersten Models nicht auf Dropout zurückführen, sondern auf das Parallelschalten der Embedding Layer. \n",
    "\n",
    "Die Idee dahinter war es neben den Pretrained Word Embedding, den tatsächlich vorkommenden Wörter im Text eine höhere Gewichtung zu verleihen.<br>\n",
    "Die Verbesserung der Performance ist insofern interessant, da auch nur mit der Verwendung des Pretrained Word Embedding die Gewichtung hinsichtlich der tatsächlich vorkommenden Wörter, mithilfe der Verbindungen zwischen den LSTM Layern, angepasst werden sollte.<br>\n",
    "Die Erkenntnis, dass es ein positiver Effekt auf ein Model haben kann, wenn zwei Embedding Layer genutzt werden, kann in zukünftigen Arbeiten von Vorteil sein.\n",
    "\n",
    "Weiterhin ist festzustellen das die Performance der dritten Architektur auf dem Testdatensatz besser war als im Training. Die zweite Architektur hat hingegen deutlich an Performance auf dem Testdatensatz verloren. \n",
    "Resultierend daraus lässt sich schlussfolgern das der vermehrte Einsatz von Dropouts einen positiven Effekt bei einem solchem Problem darstellen kann. <br>\n",
    "Außerdem kann damit gesagt das die zweite Architektur leicht overfitted ist, wodurch keine Steigerung der Performance auf den Testdaten, bei einer Steigerung der trainierten Epochen, zu erwarten ist. Allerdings wird daraus geschlussfolgert, dass die dritte Architektur mit einer Anzahl von 10 trainierten Epochen leicht underfitted ist und somit eine Steigerung der Epochen im weiteren Projektverlauf ratsam wäre. \n",
    "Leider war die Anpassung der Modelle im durch die Trainingsdauer und den zeitlich begrenzten Rahmen der Hausarbeit nicht mehr möglich. \n",
    "\n",
    "\n",
    "die Performance der Modelle könnte weiterhin mit einer Änderung der Hyperparmeter gesteigert werden.\n",
    "Bedingt durch die lange Trainingsdauer ist dies nur bedingt passiert, die erste Architektur wurde im Laufe der Hausarbeit auf verschiedenen Batchgrößen und bis zu 25 Epochen trainiert, allerdings konnte dieses Model durch Hardware technische Probleme nicht gespeichert werden. <br>\n",
    "\n",
    "\n",
    "Allerdings konnte in den Trainingsprozess beobachtet werden das bei einer Größen Epochen Anzahl die Steigerung der Accuracy nur noch im 0,01 Bereich erfolgt ist. Weshalb alle weiteren Modelle auf 10 Trainingsepochen beschränkt worden sind.\n",
    "Außerdem brachte eine Änderung der Loss Function keine Performance Steigerung mit sich.\n",
    "\n",
    "Abschließend ist zu sagen das die Aufgabe mit den gegebenen Ressourcen und den vorliegenden Architekturen deutlich zu komplex war, um ein befriedigendes Ergebnis zu erlangen. Die Generierung von Natürlicher Sprache besitzt zu viele Kombinationsmöglichkeiten, besonders bei der Wahl von Plenarprotokolle als Datengrundlage, da dort auch vermehrt Fachwörter vorkommen, die nicht im alltäglichen Sprachgebrauch relevant sind, aber dennoch für die Sinnhaftigkeit des Inhaltes erlernt werden müssen.\n",
    "\n",
    "Weiterhin ist festzuhalten, dass während der Ausarbeitung aufgefallen ist, dass klassische Metriken die normalerweise zur Evaluierung der Ergebnisse herangezogen werden, wie accuracy, precision und recall keine große Aussagekraft darüber bieten wie gute der generierte Text wirklich ist. \n",
    "Viele Wörter besitzen ähnliche Bedeutung oder können in Abhängigkeit des Kontextes auch durch andere ersetzt werden. Damit kann auch bei der Vorhersage einer falschen Klasse ein grammatikalisch und inhaltlich Sinnvoller Text generiert werden.<br>\n",
    "Bei der Recherche in laufe der Hausarbeit wurde keine zuverlässige Metrik gefunden, welches das Problem löst und den generierten Text qualitativ auf dessen Logik bewerten kann. Damit kann die Untersuchung von Zielführenderen Metriken in der Textgenerierung ein mögliches Thema weiterführende Forschung sein.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Literaturverzeichnis \n",
    "\n",
    "- Ipsos. 2020. Wie groß ist Ihrer Meinung nach der Einfluss von Künstlicher Intelligenz auf die folgenden Bereiche? Bericht, VdTÜV.\n",
    "\n",
    "- Neuhaus, Uwe, Michael Schulz, Jens Kaufmann, Badura Daniel, Kerzel Ulrich, Welter Felix, Prothmann Maik, et al. 2020. DASC-PM v1.0 - Ein Vorgehensmodell für Data-Science-Projekte. Hamburg.\n",
    "\n",
    "- Römer, Christine. 2005. Lexikologie des Deutschen. Gunter Narr Verlag.\n",
    "\n",
    "- Chigozie Enyinna Nwankpa, Winifred Ijomah, Anthony Gachagan, and Stephen Marshall. 2020. Activation Functions: Comparison of Trends in Practice and Research for Deep Learning.\n",
    "\n",
    "- Emmert-Streib F, Yang Z, Feng H, Tripathi S and Dehmer M (2020) An Introductory Review of Deep Learning for Prediction Models With Big Data. Front. Artif. Intell. 3:4. doi: 10.3389/frai.2020.00004\n",
    "\n",
    "- Bengio, Samy, and Georg Heigold. \"Word embeddings for speech recognition.\" (2014).\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "name": "hausarbeit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
